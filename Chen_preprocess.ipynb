{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "opposite-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "seed= 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-print",
   "metadata": {},
   "source": [
    "# Make label image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_label_name = os.listdir('Train_Dev/train_labels')\n",
    "\n",
    "# radius = 5\n",
    "# for label_name in all_label_name:\n",
    "#     # read image\n",
    "#     img = cv2.imread('Train_Dev/training/' + label_name.split('.')[0] + '.JPG')\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     label = pd.read_csv('Train_Dev/train_labels/' + label_name, header= None)# read label\n",
    "#     label_img = np.zeros(img.shape, dtype = 'uint8')#make label image\n",
    "    \n",
    "#     bbox = label.values\n",
    "#     for box in bbox:\n",
    "#         cv2.rectangle(label_img,\n",
    "#                       (box[0]-radius, box[1]-radius),\n",
    "#                       (box[0]+radius, box[1]+radius),\n",
    "#                       (255, 255, 255),\n",
    "#                       -1)\n",
    "#     cv2.imwrite('Train_Dev/train_labels_image/'+ label_name.split('.')[0] +'.JPG',label_img) #save labelimage\n",
    "    \n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "#     plt.imshow(label_img)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-easter",
   "metadata": {},
   "source": [
    "# Crop train image(adjust gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label_img = os.listdir('Train_Dev/train_labels_image')\n",
    "\n",
    "print(all_label_img)\n",
    "for image_name in all_label_img:\n",
    "    train_img = cv2.imread('Train_Dev/training_hist/' + image_name)# read train image\n",
    "#     train_img = cv2.cvtColor(train_img, cv2.COLOR_BGR2RGB)\n",
    "    label_img = cv2.imread('Train_Dev/train_labels_image/' + image_name)# read label image\n",
    "#     label_img = cv2.cvtColor(label_img, cv2.COLOR_BGR2RGB) \n",
    "    \n",
    "    \n",
    "    gap = 500\n",
    "    x_iter = math.ceil(train_img.shape[1]/gap)\n",
    "    y_iter = math.ceil(train_img.shape[0]/gap) \n",
    "    print(x_iter)\n",
    "    print(y_iter)\n",
    "    cnt=0\n",
    "    \n",
    "    for y in range(y_iter):\n",
    "        for x in range(x_iter):\n",
    "            cnt = cnt + 1   \n",
    "            if((x+1)*gap <= train_img.shape[1] and (y+1)*gap <= train_img.shape[0]):\n",
    "                crop_train_img = train_img[y*gap : (y+1)*gap, x*gap : (x+1)*gap]\n",
    "                crop_label_img = label_img[y*gap : (y+1)*gap, x*gap : (x+1)*gap]\n",
    "            elif((x+1)*gap > train_img.shape[1] and (y+1)*gap <= train_img.shape[0]):\n",
    "                crop_train_img = train_img[y*gap : (y+1)*gap, x*gap:]\n",
    "                crop_label_img = label_img[y*gap : (y+1)*gap, x*gap:]\n",
    "                x_gap = gap - crop_train_img.shape[1]\n",
    "                crop_train_img = cv2.copyMakeBorder(crop_train_img,0,0,0,x_gap,cv2.BORDER_REFLECT)\n",
    "                crop_label_img = cv2.copyMakeBorder(crop_label_img,0,0,0,x_gap,cv2.BORDER_REFLECT)\n",
    "            elif((x+1)*gap <= train_img.shape[1] and (y+1)*gap > train_img.shape[0]):\n",
    "                crop_train_img = train_img[y*gap:, x*gap : (x+1)*gap]\n",
    "                crop_label_img = label_img[y*gap:, x*gap : (x+1)*gap]\n",
    "                y_gap = gap - crop_train_img.shape[0]\n",
    "                crop_train_img = cv2.copyMakeBorder(crop_train_img,0,y_gap,0,0,cv2.BORDER_REFLECT)\n",
    "                crop_label_img = cv2.copyMakeBorder(crop_label_img,0,y_gap,0,0,cv2.BORDER_REFLECT)\n",
    "            else:\n",
    "                crop_train_img = train_img[y*gap:, x*gap:]\n",
    "                crop_label_img = label_img[y*gap:, x*gap:]\n",
    "                x_gap = gap - crop_train_img.shape[1]\n",
    "                y_gap = gap - crop_train_img.shape[0]\n",
    "                crop_train_img = cv2.copyMakeBorder(crop_train_img,0,y_gap,0,x_gap,cv2.BORDER_REFLECT)\n",
    "                crop_label_img = cv2.copyMakeBorder(crop_label_img,0,y_gap,0,x_gap,cv2.BORDER_REFLECT)\n",
    "        \n",
    "            cv2.imwrite('Train_Dev/crop_training_500_hist/'+ image_name.split('.')[0] +'_'+ str(cnt) +'.JPG',crop_train_img) #save labelimage\n",
    "#             cv2.imwrite('Train_Dev/crop_trainlabel_image_512/'+ image_name.split('.')[0] +'_'+ str(cnt) +'.JPG',crop_label_img) #save labelimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-vanilla",
   "metadata": {},
   "source": [
    "# Crop test image(adjust gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "isolated-cricket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DSC080633.JPG', 'DSC080733.JPG', 'DSC080823.JPG', 'DSC080994.JPG', 'DSC081024.JPG', 'DSC081034.JPG', 'DSC081133.JPG', 'DSC081152.JPG', 'DSC081433.JPG', 'DSC081494.JPG', 'DSC081543.JPG', 'DSC081723.JPG', 'DSC082013.JPG', 'DSC082111.JPG', 'DSC082113.JPG', 'DSC082121.JPG', 'DSC082124.JPG', 'DSC082143.JPG', 'DSC082153.JPG', 'DSC082453.JPG', 'DSC082454.JPG', 'DSC082754.JPG', 'DSC082762.JPG', 'DSC082781.JPG', 'DSC082821.JPG', 'IMG_170406_035957_0043_RGB2.JPG', 'IMG_170406_040021_0063_RGB2.JPG', 'IMG_170406_040041_0079_RGB3.JPG', 'IMG_170406_040105_0099_RGB1.JPG', 'IMG_170406_040108_0102_RGB1.JPG', 'IMG_170406_040124_0115_RGB1.JPG', 'IMG_170406_040157_0143_RGB3.JPG', 'IMG_170406_040301_0196_RGB1.JPG', 'IMG_170406_040351_0238_RGB1.JPG', 'IMG_170406_040354_0240_RGB2.JPG', 'IMG_170406_040355_0241_RGB1.JPG', 'IMG_170406_040356_0242_RGB1.JPG', 'IMG_170406_040356_0242_RGB4.JPG', 'IMG_170406_040400_0245_RGB1.JPG', 'IMG_170406_040400_0245_RGB3.JPG', 'IMG_170406_040400_0245_RGB4.JPG', 'IMG_170406_040406_0250_RGB2.JPG', 'IMG_170406_040406_0250_RGB4.JPG', 'IMG_170406_040408_0252_RGB1.JPG', 'IMG_170406_040408_0252_RGB4.JPG', 'IMG_170406_040409_0253_RGB4.JPG', 'IMG_170406_040411_0254_RGB3.JPG']\n"
     ]
    }
   ],
   "source": [
    "# test_public_img = os.listdir('test_public/')\n",
    "test_private_img =  os.listdir('test_private/')\n",
    "print(test_public_img)\n",
    "for image_name in test_private_img:\n",
    "    train_img = cv2.imread('test_private/' + image_name)# read train image\n",
    "#     train_img = cv2.cvtColor(train_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "    gap = 256\n",
    "    if(train_img.shape[1]%gap == 0):\n",
    "        x_iter = train_img.shape[1]//gap\n",
    "    else:\n",
    "        x_iter = train_img.shape[1]//gap+1\n",
    "    if(train_img.shape[0]%gap == 0):\n",
    "        y_iter = train_img.shape[0]//gap\n",
    "    else:\n",
    "        y_iter = train_img.shape[0]//gap+1\n",
    "        \n",
    "    cnt=0\n",
    "    for y in range(y_iter):\n",
    "        for x in range(x_iter):\n",
    "            cnt = cnt + 1   \n",
    "            if((x+1)*gap <= train_img.shape[1] and (y+1)*gap <= train_img.shape[0]):\n",
    "                crop_train_img = train_img[y*gap : (y+1)*gap, x*gap : (x+1)*gap]\n",
    "            elif((x+1)*gap > train_img.shape[1] and (y+1)*gap <= train_img.shape[0]):\n",
    "                crop_train_img = train_img[y*gap : (y+1)*gap, x*gap:]\n",
    "                x_gap = gap - crop_train_img.shape[1]\n",
    "                crop_train_img = cv2.copyMakeBorder(crop_train_img,0,0,0,x_gap,cv2.BORDER_REFLECT)\n",
    "            elif((x+1)*gap <= train_img.shape[1] and (y+1)*gap > train_img.shape[0]):\n",
    "                crop_train_img = train_img[y*gap:, x*gap : (x+1)*gap]\n",
    "                y_gap = gap - crop_train_img.shape[0]\n",
    "                crop_train_img = cv2.copyMakeBorder(crop_train_img,0,y_gap,0,0,cv2.BORDER_REFLECT)\n",
    "            else:\n",
    "                crop_train_img = train_img[y*gap:, x*gap:]\n",
    "                x_gap = gap - crop_train_img.shape[1]\n",
    "                y_gap = gap - crop_train_img.shape[0]\n",
    "                crop_train_img = cv2.copyMakeBorder(crop_train_img,0,y_gap,0,x_gap,cv2.BORDER_REFLECT)\n",
    "        \n",
    "            cv2.imwrite('test/crop_test_private_256/'+ image_name.split('.')[0] +'_'+ str(cnt) +'.JPG',crop_train_img) #save labelimage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-wholesale",
   "metadata": {},
   "source": [
    "# reflect_test_function(fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_image(input_img, target_y, target_x):\n",
    "    if(input_img.shape[0] == target_y and input_img.shape[1] != target_x):\n",
    "        tmp_img = np.flip(input_img[:,-(target_x-input_img.shape[1]):],1)\n",
    "        print('shape of tmp_img:' + str(tmp_img.shape))\n",
    "        new_img = np.concatenate((input_img,tmp_img),axis=1)\n",
    "    elif(input_img.shape[1] == target_x and input_img.shape[0] != target_y):\n",
    "        tmp_img2 = np.flip(input_img[-(target_y-input_img.shape[0]) : , : ], 0)\n",
    "        print(-(target_y-input_img.shape[0]))\n",
    "        print('shape of tmp_img:' + str(tmp_img2.shape))\n",
    "        new_img = np.concatenate((input_img,tmp_img2),axis=0)\n",
    "    return(new_img)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-vulnerability",
   "metadata": {},
   "source": [
    "# reflect_test(fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label_img = os.listdir('Train_Dev/train_labels_image')\n",
    "\n",
    "# print(all_label_img)\n",
    "train_img = cv2.imread('Train_Dev/training/' + all_label_img[-1])\n",
    "label_img = cv2.imread('Train_Dev/train_labels_image/' + all_label_img[-1])\n",
    "print(train_img.shape[0])\n",
    "print(train_img.shape[1])\n",
    "cnt=0\n",
    "gap = 500\n",
    "# crop_train_img = train_img[2*gap : 3*gap , 4*gap :]\n",
    "# crop_label_img = label_img[2*gap : 3*gap , 4*gap :]\n",
    "# t_reflect = cv2.copyMakeBorder(crop_train_img,0,0,0,196,cv2.BORDER_REFLECT)\n",
    "# l_reflect = cv2.copyMakeBorder(crop_label_img,0,0,0,196,cv2.BORDER_REFLECT)\n",
    "\n",
    "# plt.imshow(crop_train_img)\n",
    "# plt.show()\n",
    "# plt.imshow(crop_label_img)\n",
    "# plt.show()\n",
    "# plt.imshow(t_reflect)\n",
    "# plt.show()\n",
    "# plt.imshow(l_reflect)\n",
    "# plt.show()\n",
    "# print(crop_train_img.shape)\n",
    "\n",
    "# # reflect = cv2.copyMakeBorder(crop_train_img,0,0,0,196,cv2.BORDER_REFLECT)\n",
    "\n",
    "\n",
    "# new_img = fill_image(crop_train_img, 500, 500)\n",
    "# new_label = fill_image(crop_label_img, 500, 500)\n",
    "# plt.imshow(new_img)\n",
    "# plt.show()\n",
    "# plt.imshow(new_label)\n",
    "# plt.show()\n",
    "# print(new_label.shape)  \n",
    "# ----------------------------------------------------\n",
    "# crop_train_img = train_img[3*gap: , 3*gap:4*gap]\n",
    "# crop_label_img = label_img[3*gap: , 3*gap:4*gap]\n",
    "# print(crop_train_img.shape)\n",
    "# plt.imshow(crop_train_img)\n",
    "# plt.show()\n",
    "# plt.imshow(crop_label_img)\n",
    "# plt.show()\n",
    "\n",
    "# t_reflect = cv2.copyMakeBorder(crop_train_img,0,272,0,0,cv2.BORDER_REFLECT)\n",
    "# l_reflect = cv2.copyMakeBorder(crop_label_img,0,272,0,0,cv2.BORDER_REFLECT)\n",
    "# plt.imshow(t_reflect)\n",
    "# plt.show()\n",
    "# plt.imshow(l_reflect)\n",
    "# plt.show()\n",
    "# print(t_reflect.shape)    \n",
    "# print(l_reflect.shape)  \n",
    "\n",
    "# new_img = fill_image(crop_train_img, 500, 500)\n",
    "# new_label = fill_image(crop_label_img, 500, 500)\n",
    "# plt.imshow(new_img)\n",
    "# plt.show()\n",
    "# plt.imshow(new_label)\n",
    "# plt.show()\n",
    "# print(new_img.shape)    \n",
    "# print(new_label.shape)    \n",
    "# ----------------------------------------\n",
    "crop_train_img = train_img[3*gap: , 4*gap:]\n",
    "crop_label_img = label_img[3*gap: , 4*gap:]\n",
    "\n",
    "y_gap = gap - crop_train_img.shape[0]\n",
    "x_gap = gap - crop_train_img.shape[1]\n",
    "\n",
    "print(crop_train_img.shape)\n",
    "plt.imshow(crop_train_img)\n",
    "plt.show()\n",
    "plt.imshow(crop_label_img)\n",
    "plt.show()\n",
    "\n",
    "t_reflect = cv2.copyMakeBorder(crop_train_img,0,y_gap,0,x_gap,cv2.BORDER_REFLECT)\n",
    "l_reflect = cv2.copyMakeBorder(crop_label_img,0,y_gap,0,x_gap,cv2.BORDER_REFLECT)\n",
    "plt.imshow(t_reflect)\n",
    "plt.show()\n",
    "plt.imshow(l_reflect)\n",
    "plt.show()\n",
    "print(t_reflect.shape)    \n",
    "print(l_reflect.shape)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-bridal",
   "metadata": {},
   "source": [
    "# flip and concatenate test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed= 1\n",
    "np.random.seed(seed)\n",
    "a = np.random.randn(4,5)\n",
    "print(type(train_img))\n",
    "b = a[-3:,:]\n",
    "c = np.flip(b,0)\n",
    "print(a)\n",
    "print(b)\n",
    "print(np.flip(b,0))\n",
    "print(np.flip(b,1))\n",
    "print(np.concatenate((a,c),axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3,4]\n",
    "b=[1,4,5,7]\n",
    "c=[1,5,8,7]\n",
    "df = pd.DataFrame(list(zip(a, b, c)),\n",
    "               columns =['Name', 'val','dsfasd'])\n",
    "print(df)\n",
    "\n",
    "\n",
    "# filename ='result.csv'\n",
    "# def OutputCSV(filename):   \n",
    "#     df = pd.DataFrame.from_dict( SAMPLE_List )\n",
    "#     df.to_csv( filename  , index=False )\n",
    "#     print( '成功產出'+filename )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label_name = os.listdir('Train_Dev/train_labels')\n",
    "\n",
    "radius = 5\n",
    "for label_name in all_label_name[0:1]:\n",
    "    # read image\n",
    "    img = cv2.imread('Train_Dev/training/' + label_name.split('.')[0] + '.JPG')\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    label = pd.read_csv('Train_Dev/train_labels/' + label_name, header= None)# read label\n",
    "#     label_img = np.zeros(img.shape, dtype = 'uint8')#make label image\n",
    "    \n",
    "    bbox = label.values\n",
    "    for box in bbox:\n",
    "        cv2.rectangle(img,\n",
    "                      (box[0]-radius, box[1]-radius),\n",
    "                      (box[0]+radius, box[1]+radius),\n",
    "                      (255, 255, 255),\n",
    "                      -1)\n",
    "    cv2.imwrite('exp_result/figure/analysis/'+ label_name.split('.')[0] +'.JPG',img) #save labelimage\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "#     plt.imshow(label_img)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continuous-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label_name = os.listdir('test/crop_test_private_256/')\n",
    "for label_name in all_label_name:\n",
    "    # read image\n",
    "    img = cv2.imread('test/crop_test_private_256/' + label_name.split('.')[0] + '.JPG')\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "    img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "    \n",
    "    cv2.imwrite('test/crop_test_private_256_hist/'+ label_name.split('.')[0] +'.JPG',img_output)\n",
    "#     img_output = cv2.cvtColor(img_output, cv2.COLOR_BGR2RGB)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     plt.figure(figsize=(15,10))\n",
    "#     plt.imshow(img_output)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.figure(figsize=(15,10))\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "#     cv2.imwrite('Train_Dev/training_hist/'+ label_name.split('.')[0] +'.JPG',label_img) #save labelimage\n",
    "#     print('-----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a2396",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt=['a','b','c']\n",
    "tt.index('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b5329",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0.6 ,0.7 ,0.4])\n",
    "\n",
    "c = a>0.5\n",
    "print(c.dtype)\n",
    "\n",
    "print(c.astype(float))\n",
    "b = a>0.6\n",
    "print(b+c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c1d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
